import time
import sys
import os
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from crawler import WebCrawler
from database import DatabaseManager
from pagerank_mapreduce import MapReducePageRank
from pagerank_pregel import PageRankPregel
from search_engine import SearchEngine
from config import Config


def print_header(text: str):
    """–ü–µ—á–∞—Ç—å –∑–∞–≥–æ–ª–æ–≤–∫–∞"""
    print("\n" + "=" * 80)
    print(f" {text.upper()}")
    print("=" * 80)


def demo_full_pipeline():
    """–ü–æ–ª–Ω–∞—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –≤—Å–µ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ —Å–∏—Å—Ç–µ–º—ã"""
    
    # 1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    print_header("1. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã")
    Config.init_database()
    
    db = DatabaseManager()
    
    # –û–±—ä—è–≤–ª—è–µ–º –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞—Ä–∞–Ω–µ–µ
    mr_time = 0
    pregel_time = 0
    pagerank_mr = None
    pagerank_pregel = None
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å—Ç—å –ª–∏ —É–∂–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã
    doc_count = db.get_document_count()
    if doc_count > 10:
        print(f"2. –í –±–∞–∑–µ —É–∂–µ –µ—Å—Ç—å {doc_count} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤. –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∫—Ä–∞—É–ª–∏–Ω–≥.")
    else:
        # 2. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö
        print_header("2. –°–±–æ—Ä –¥–∞–Ω–Ω—ã—Ö —Å –≤–µ–±-—Å–∞–π—Ç–æ–≤")
        crawler = WebCrawler()
        crawler.crawl()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –ø–æ—Å—Ç—Ä–æ–µ–Ω –ª–∏ –∏–Ω–¥–µ–∫—Å
    cursor = db.conn.cursor()
    cursor.execute("SELECT COUNT(*) FROM document_words")
    index_count = cursor.fetchone()[0]
    
    if index_count > 0:
        print(f"3. –ò–Ω–¥–µ–∫—Å —É–∂–µ –ø–æ—Å—Ç—Ä–æ–µ–Ω ({index_count} –∑–∞–ø–∏—Å–µ–π). –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∏–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ.")
    else:
        # 3. –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ
        print_header("3. –ò–Ω–¥–µ–∫—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤")
        db.build_index()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –≤—ã—á–∏—Å–ª–µ–Ω –ª–∏ PageRank (–Ω–µ —Ä–∞–≤–µ–Ω –∑–Ω–∞—á–µ–Ω–∏—é –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 1.0)
    cursor.execute("SELECT COUNT(*) FROM documents WHERE pagerank != 1.0")
    pr_calculated = cursor.fetchone()[0]
    
    if pr_calculated > 0:
        print(f"4-5. PageRank —É–∂–µ –≤—ã—á–∏—Å–ª–µ–Ω –¥–ª—è {pr_calculated} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤.")
        print("\n–ò—Å–ø–æ–ª—å–∑—É–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏—è –∏–∑ –±–∞–∑—ã.")
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç—ã –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –º–µ—Ç–æ–¥–∞–º get_top_documents
        pagerank_mr = MapReducePageRank()
        pagerank_pregel = PageRankPregel(Config.DB_PATH)
        
    else:
        # 4. PageRank —á–µ—Ä–µ–∑ MapReduce
        print_header("4. PageRank —á–µ—Ä–µ–∑ MapReduce")
        start_time = time.time()
        pagerank_mr = MapReducePageRank()
        pagerank_mr.update_database()
        mr_time = time.time() - start_time
        
        # 5. PageRank —á–µ—Ä–µ–∑ Pregel
        print_header("5. PageRank —á–µ—Ä–µ–∑ Pregel")
        start_time = time.time()
        pagerank_pregel = PageRankPregel(Config.DB_PATH)
        pagerank_pregel.update_database()
        pregel_time = time.time() - start_time
        
        print(f"\n–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è MapReduce: {mr_time:.2f} —Å–µ–∫")
        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è Pregel: {pregel_time:.2f} —Å–µ–∫")
    
    # 6. –¢–æ–ø –¥–æ–∫—É–º–µ–Ω—Ç—ã –ø–æ PageRank
    print_header("6. –¢–æ–ø-10 –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –ø–æ PageRank")
    
    if pagerank_mr and pagerank_pregel:
        print("\nMapReduce —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        top_mr = pagerank_mr.get_top_documents(5)
        for i, doc in enumerate(top_mr, 1):
            print(f"  {i}. {doc['title'][:50]}... - PR: {doc['pagerank']:.6f}")
        
        print("\nPregel —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã:")
        top_pregel = pagerank_pregel.get_top_documents(5)
        for i, doc in enumerate(top_pregel, 1):
            print(f"  {i}. {doc['title'][:50]}... - PR: {doc['pagerank']:.6f}")
    
    # 7. –ü–æ–∏—Å–∫
    print_header("7. –î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –ø–æ–∏—Å–∫–∞")
    
    se = SearchEngine()
    
    test_queries = [
        "machine learning algorithm",
        "data science techniques",
        "web crawler search",
        "artificial intelligence future"
    ]
    
    for query in test_queries:
        print(f"\nüîç –ó–∞–ø—Ä–æ—Å: '{query}'")
        print("-" * 70)
        
        # Document-at-a-time
        print("Document-at-a-time –ø–æ–¥—Ö–æ–¥:")
        results_doc = se.search(query, method='doc_at_a_time', k=3)
        for i, result in enumerate(results_doc, 1):
            print(f"  {i}. {result['title']}")
            print(f"     –†–µ–π—Ç–∏–Ω–≥: {result['score']:.2f} | PR: {result['pagerank']:.6f}")
        
        # Term-at-a-time
        print("\nTerm-at-a-time –ø–æ–¥—Ö–æ–¥:")
        results_term = se.search(query, method='term_at_a_time', k=3)
        for i, result in enumerate(results_term, 1):
            print(f"  {i}. {result['title']}")
            print(f"     –†–µ–π—Ç–∏–Ω–≥: {result['score']:.2f} | PR: {result['pagerank']:.6f}")
    
    # 8. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫
    print_header("8. –ò–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω—ã–π –ø–æ–∏—Å–∫")
    
    while True:
        print("\n–í–≤–µ–¥–∏—Ç–µ –ø–æ–∏—Å–∫–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å (–∏–ª–∏ 'quit' –¥–ª—è –≤—ã—Ö–æ–¥–∞):")
        query = input("> ").strip()
        
        if query.lower() in ['quit', 'exit', 'q']:
            break
        
        if not query:
            continue
        
        print(f"\n–†–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è: '{query}'")
        print("-" * 70)
        
        # Document-at-a-time
        results_doc = se.search(query, method='doc_at_a_time', k=5)
        print("\nüìÑ Document-at-a-time (–ø–µ—Ä–≤—ã–µ 5):")
        for i, result in enumerate(results_doc, 1):
            print(f"  {i}. [{result['score']:.2f}] {result['title']}")
            print(f"     {result['url']}")
        
        # Term-at-a-time
        results_term = se.search(query, method='term_at_a_time', k=5)
        print("\nüî§ Term-at-a-time (–ø–µ—Ä–≤—ã–µ 5):")
        for i, result in enumerate(results_term, 1):
            print(f"  {i}. [{result['score']:.2f}] {result['title']}")
            print(f"     {result['url']}")
    
    se.close()
    db.close()
    
    print_header("–î–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")


if __name__ == "__main__":
    demo_full_pipeline()
